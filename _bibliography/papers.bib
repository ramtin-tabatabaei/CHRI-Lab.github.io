%%%%% 2025

@article{ramtin2025b,
bibtex_show={true},
  title={Real-Time Detection of Robot Failures Using Gaze Dynamics in Collaborative Tasks},
  author = {Tabatabaei, Ramtin and Kostakos, Vassilis and Johal, Wafa},
  booktitle={Proceedings of the 2025 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
  organization={IEEE},
  pdf = {https://chri-lab.github.io/files/papers/ramtin2025b_lbr.pdf},
  year={2025}
}


@article{schombs2024exploring2,
  bibtex_show={true},
  title={Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations},
  author={Sch{\"o}mbs, Sarah and Goncalves, Jorge and Johal, Wafa},
  journal={arXiv preprint arXiv:2402.04598},
  pdf = {https://chri-lab.github.io/files/papers/schombs2023.pdf},
  year={2024}, 
  project={robotvis}
}


%%%%% 2024 
@inproceedings{bilal2024,
bibtex_show={true},
  title={Beyond Success: Quantifying Demonstration Quality in Learning from Demonstration},
  author={Bilal, Muhammad and Lipovetzky, Nir and Oetomo, Denny and Johal, Wafa},
  booktitle={2024 IEEE/RSJ International conference on Intelligent Robots and Systems (IROS)},
  organization={IEEE},
  pdf = {https://wafajohal.github.io/files/papers/bilal2024.pdf},
  year={2024}
}


@inproceedings{ulan2024,
bibtex_show={true},
  title={Stuet: Dual Stewart Platforms for Pinch Grasping Objects in VR},
  author={Kelesbekov, Ulan and Marini, Gabriele  and Zhongyi, Bai and Johal, Wafa and Velloso, Eduardo and Knibbe, Jarrod},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  organization={IEEE},
  pdf = {https://wafajohal.github.io/files/papers/ulan2024_ISMAR.pdf},
  year={2024},
  video={https://youtu.be/iz-NdM2Bp2U}
}

@article{schombs2024exploring,
  bibtex_show={true},
  title={Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations},
  author={Sch{\"o}mbs, Sarah and Goncalves, Jorge and Johal, Wafa},
  journal={arXiv preprint arXiv:2402.04598},
  pdf = {https://chri-lab.github.io/files/papers/schombs2023.pdf},
  year={2024}, 
  project={robotvis}
}





@article{pan2024,
  bibtex_show={true},
  author={Pan, Jiahe and Eden, Jonathan and Oetomo, Denny and Johal, Wafa},
  journal={IEEE Robotics and Automation Letters}, 
  title={Effects of Shared Control on Cognitive Load and Trust in Teleoperated Trajectory Tracking}, 
  year={2024},
  volume={9},
  number={6},
  pages={5863-5870},
  video = {https://youtu.be/yizsBG1QJog},
  doi={10.1109/LRA.2024.3396111},
  pdf = {https://chri-lab.github.io/files/papers/pan2024.pdf},
  selected = 	 {yes}
}

@inproceedings{schombs2024b,
  bibtex_show={true},
  author = {Sch{\"o}mbs, Sarah and Pareek, Saumya and Goncalves, Jorge and Johal, Wafa},
  title = {Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year = {2024},
  month = {May},
  dates = {11--16},
  location = {Honolulu, HI, USA},
  acmDOI = {10.1145/3613904.3642911},
  acmISBN = {979-8-4007-0330-0/24/05},
  publisher = {ACM},
  pdf = {https://chri-lab.github.io/files/papers/schombs2024.pdf},
  video = {https://youtu.be/8zgKpGTkMCI},
  selected = 	 {yes}, 
  project={robotvis}
}

@article{schombs2024facevis,
  bibtex_show={true},
  title={FaceVis: Exploring a Robot’s Face for Affective Visualisation Design},
  author={Sch{\"o}mbs, Sarah and Pan, Jiahe and Zhang, Yan and Goncalves, Jorge and Johal, Wafa},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  pdf = {https://chri-lab.github.io/files/papers/schombs2024b.pdf},
  year={2024}, 
  video = {https://youtu.be/Q1H0tA2EWy8},
  website = {https://sites.google.com/view/facevis/home},
  selected = 	 {yes},
  project={robotvis}
}

@inproceedings{admoni2024,
  bibtex_show={true},
author = {Admoni, Henny and Johal, Wafa and Szafir, Daniel and Sandygulova, Anara},
title = {Designing an Introductory HRI Course},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638165},
doi = {10.1145/3610978.3638165},
abstract = {Human-robot interaction is now an established discipline. Dozens of HRI courses exist at universities worldwide, and some institutions even offer degrees in HRI. However, although many students are being taught HRI, there is no agreed-upon curriculum for an introductory HRI course. In this workshop, we aim to reach community consensus on what should be covered in such a course. Through interactive activities like panels, breakout discussions, and syllabus design, workshop participants will explore the many topics and pedagogical approaches for teaching HRI. They will then distill their findings into a single example introductory HRI curriculum. Output from this workshop will include a short paper explaining this curriculum and an example syllabus that can be used and adapted by HRI educators.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1302–1304},
numpages = {3},
keywords = {human-robot interaction, pedagogy},
location = {Boulder,CO,USA},
pdf = {https://chri-lab.github.io/files/papers/admoni2024.pdf},
series = {HRI '24}
}

@inproceedings{Yadollahi2024,
  bibtex_show={true},
author = {Yadollahi, Elmira and Romeo, Marta and Dogan, Fethiye Irmak and Johal, Wafa and De Graaf, Maartje and Levy-Tzedek, Shelly and Leite, Iolanda},
title = {Explainability for Human-Robot Collaboration},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638154},
pdf = {https://chri-lab.github.io/files/papers/yadollahi.pdf},
doi = {10.1145/3610978.3638154},
abstract = {In human-robot collaboration, explainability bridges the communication gap between complex machine functionalities and humans. An active area of investigation in robotics and AI is understanding and generating explanations that can enhance collaboration and mutual understanding between humans and machines. A key to achieving such seamless collaborations is understanding end-users, whether naive or expert, and tailoring explanation features that are intuitive, user-centred, and contextually relevant. Advancing on the topic not only includes modelling humans' expectations for generating the explanations but also requires the development of metrics to evaluate generated explanations and assess how effectively autonomous systems communicate their intentions, actions, and decision-making rationale. This workshop is designed to tackle the nuanced role of explainability in enhancing the efficiency, safety, and trust in human-robot collaboration. It aims to initiate discussions on the importance of generating and evaluating explainability features developed in autonomous agents. Simultaneously, it addresses various challenges, including bias in explainability and downsides of explainability and deception in human-robot interaction.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1364–1366},
numpages = {3},
keywords = {XAI, explainable robotics, human-centered robot explanations},
location = {Boulder,CO,USA},
series = {HRI '24}
}

@article{johal2024transferability,
  bibtex_show={true},
  title={Transferability of HRI Research: Potential and Challenges},
  author={Johal, Wafa},
  journal={arXiv preprint arXiv:2401.05802},
  year={2024}
}

%%%%% 2023

@inproceedings{tozadore2023robots,
  title={Robots for Learning 7 (R4L) A Look from Stakeholders' Perspective},
  author={Tozadore, Daniel C and Nasir, Jauwairia and Gillet, Sarah and van den Berghe, Rianne and Guneysu, Arzu and Johal, Wafa},
  booktitle={Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={935--937},
  year={2023}
}


@inproceedings{phaijit2023user,
  bibtex_show={true},
  title={User Interface Interventions for Improving Robot Learning from Demonstration},
  author={Phaijit, Ornnalin and Sammut, Claude and Johal, Wafa},
  booktitle={Proceedings of the 11th International Conference on Human-Agent Interaction},
  pdf = {https://chri-lab.github.io/files/papers/phaijit2021.pdf},
  pages={152--161},
  year={2023},
  selected = 	 {yes}
}

@inproceedings{gamboa2023championing,
  bibtex_show={true},
  title={Championing Design Knowledge in Human-Drone Interaction Research},
  author={Gamboa, Mafalda and Ljungblad, Sara and Johal, Wafa and Mubin, Omar and Obaid, Mohammad},
  booktitle={Proceedings of the 11th International Conference on Human-Agent Interaction},
  pages={365--368},
  year={2023}
}


@inproceedings{liu2023speech,
  bibtex_show={true},
  title={Speech-Gesture GAN: Gesture Generation for Robots and Embodied Agents},
  author={Liu, Carson Yu and Mohammadi, Gelareh and Song, Yang and Johal, Wafa},
  booktitle={2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={405--412},
  year={2023},
  organization={IEEE}
}


%%%%% 2022
@inproceedings{phaijit2022let,
  bibtex_show={true},
  title={Let’s Compete! The Influence of Human-Agent Competition and Collaboration on Agent Learning and Human Perception},
  author={Phaijit, Ornnalin and Sammut, Claude and Johal, Wafa},
  booktitle={Proceedings of the 10th International Conference on Human-Agent Interaction},
  pages={86--94},
  year={2022}
}


@article{johal2022envisioning,
  bibtex_show={true},
  title={Envisioning social drones in education},
  author={Johal, Wafa and Gatos, Do{\u{g}}a and Yantac, Asim Evren and Obaid, Mohammad},
  journal={Frontiers in Robotics and AI},
  volume={9},
  pages={666736},
  year={2022},
  publisher={Frontiers}
}

@inproceedings{obaid2022social,
  bibtex_show={true},
  title={Social Drones for Health and Well-being},
  author={Obaid, Mohammad and Tatar, K{\i}van{\c{c}} and Wiberg, Mikael and Said, Alan and Rost, Mattias and Weilenmann, Alexandra and Johal, Wafa and Eyssel, Friederike},
  booktitle={Adjunct Proceedings of the 2022 Nordic Human-Computer Interaction Conference},
  pages={1--4},
  year={2022}
}

@article{johal2022robots,
  bibtex_show={true},
  title={Robots for learning},
  author={Johal, Wafa and Belpaeme, Tony and Chetouani, Mohamed},
  journal={Frontiers in Robotics and AI},
  volume={9},
  pages={1050658},
  year={2022},
  publisher={Frontiers}
}

@inproceedings{rakhymbayeva2022transfer,
  bibtex_show={true},
  title={To Transfer or Not To Transfer: Engagement Recognition within Robot-assisted Autism Therapy},
  author={Rakhymbayeva, Nazerke and Balgabekova, Zarema and Nurmukhamed, Mukhamedzhan and Burunchina, Karina and Johal, Wafa and Sandygulova, Anara},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={1002--1006},
  year={2022},
  organization={IEEE}
}
@inproceedings{fourie2022joint,
  title={Joint action, adaptation, and entrainment in human-robot interaction},
  author={Fourie, Christopher and Figueroa, Nadia and Shah, Julie and Bie{\'n}kiewicz, Marta and Bardy, Beno{\^\i}t and Burdet, Etienne and Singamaneni, Phani Teja and Alami, Rachid and Curioni, Arianna and Knoblich, G{\"u}nther and others},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={1250--1253},
  year={2022},
  organization={IEEE}
}
@inproceedings{phaijit2022taxonomy,
  bibtex_show={true},
  title={A Taxonomy of Functional Augmented Reality for Human-Robot Interaction},
  author={Phaijit, Ornnalin and Obaid, Mohammad and Sammut, Claude and Johal, Wafa},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={294--303},
  year={2022},
  organization={IEEE}
}

@inbook{Bruno2023,
  bibtex_show={true},
	abstract = {Education is one of the predominant applications that is foreseen by researchers in social roboticsSocial robotics. In this context, social robots are often designed to interact with one or several learners and with teachers. While educational scenarios for social robots have been studied widely, with experiments being conducted in several countries for nearly 20 years, the cultural impact of accepting social robots in classrooms is still unclear. In this paper, we review the literature on social robots for education with the lens of cultural sensitivity and adaptation. We discuss culture theories and their application in social roboticsSocial robotics and highlight research gaps in terms of culture-sensitive design and cultural adaptation in social robots assisting learners in terms of (1) the robot's role, (2) envisioned tasks, and (3) interaction types. We also present guidelines for designing cross-cultural robots and culturally adaptive systems.},
	address = {Cham},
	author = {Bruno, Barbara and Amirova, Aida and Sandygulova, Anara and Lugrin, Birgit and Johal, Wafa},
	booktitle = {Cultural Robotics: Social Robots and Their Emergent Cultural Ecologies},
	doi = {10.1007/978-3-031-28138-9_9},
	editor = {Dunstan, Belinda J. and Koh, Jeffrey T. K. V. and Turnbull Tillman, Deborah and Brown, Scott Andrew},
	isbn = {978-3-031-28138-9},
	pages = {127--145},
	publisher = {Springer International Publishing},
	title = {Culture in Social Robots for Education},
	url = {https://doi.org/10.1007/978-3-031-28138-9_9},
	year = {2023}
  }


@inproceedings{phaijit2022demonstration,
  bibtex_show={true},
  title={A Demonstration of the Taxonomy of Functional Augmented Reality for Human-Robot Interaction},
  author={Phaijit, Ornnalin and Obaid, Mohammad and Sammut, Claude and Johal, Wafa},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={981--985},
  year={2022},
  organization={IEEE}
}

@article{olsen2022leveraging,
  bibtex_show={true},
  title={Leveraging eye tracking to understand children’s attention during game-based, tangible robotics activities},
  author={Olsen, Jennifer K and Ozgur, Arzu Guneysu and Sharma, Kshitij and Johal, Wafa},
  journal={International Journal of Child-Computer Interaction},
  volume={31},
  pages={100447},
  year={2022},
  publisher={Elsevier}
}

@article{ozgur2022effect,
  bibtex_show={true},
  title = {The effect of gamified robot-enhanced training on motor performance in chronic stroke survivors},
  journal = {Heliyon},
  volume = {8},
  number = {11},
  pages = {e11764},
  year = {2022},
  issn = {2405-8440},
  doi = {https://doi.org/10.1016/j.heliyon.2022.e11764},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844022030523},
  author = {Arzu Guneysu Ozgur and Maximilian J. Wessel and Jennifer K. Olsen and Andéol Geoffroy Cadic-Melchior and Valérie Zufferey and Wafa Johal and Giulia Dominijanni and Jean-Luc Turlan and Andreas Mühl and Barbara Bruno and Philippe Vuadens and Pierre Dillenbourg and Friedhelm C. Hummel},
  keywords = {Gamification, Robotics, Stroke, Motor rehabilitation, Robot-assisted training, Personalization},
  abstract = {Task-specific training constitutes a core element for evidence-based rehabilitation strategies targeted at improving upper extremity activity after stroke. Its combination with additional treatment strategies and neurotechnology-based solutions could further improve patients' outcomes. Here, we studied the effect of gamified robot-assisted upper limb motor training on motor performance, skill learning, and transfer with respect to a non-gamified control condition with a group of chronic stroke survivors. The results suggest that a gamified training strategy results in more controlled motor performance during the training phase, which is characterized by a higher accuracy (lower deviance), higher smoothness (lower jerk), but slower speed. The responder analyses indicated that mildly impaired patients benefited most from the gamification approach. In conclusion, gamified robot-assisted motor training, which is personalized to the individual capabilities of a patient, constitutes a promising investigational strategy for further improving motor performance after a stroke.}
  }

  @article{gargot2022automatic,
  bibtex_show={true},
  title={Automatic assessment of motor impairments in Autism Spectrum Disorders: a systematic review},
  author={Gargot, Thomas and Archambault, Dominique and Chetouani, Mohamed and Cohen, David and Johal, Wafa and Anzalone, Salvatore Maria},
  journal={Cognitive Computation},
  volume={14},
  number={2},
  pages={624--659},
  year={2022},
  publisher={Springer}
}

%%%%% 2021
@article{amirova202110,
  bibtex_show={true},
  title={10 years of human-nao interaction research: A scoping review},
  author={Amirova, Aida and Rakhymbayeva, Nazerke and Yadollahi, Elmira and Sandygulova, Anara and Johal, Wafa},
  journal={Frontiers in Robotics and AI},
  volume={8},
  pages={744526},
  year={2021},
  publisher={Frontiers}
}
@inproceedings{liu2021speech,
  bibtex_show={true},
  title={Speech-based gesture generation for robots and embodied agents: A scoping review},
  author={Liu, Yu and Mohammadi, Gelareh and Song, Yang and Johal, Wafa},
  booktitle={Proceedings of the 9th International Conference on Human-Agent Interaction},
  pages={31--38},
  year={2021}
}
@inproceedings{ingle2021,
  bibtex_show={true},
  title           = {The Valley of non-Distraction: Effect of Robot's Human-likeness on Perception Load},
  year            = {2021},
  author          = {Ingle, Daisy and Marcus, Nadine and Johal, Wafa},
  booktitle       = {Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21 Companion), March 8--11, 2021, Boulder,CO, USA},
  publisher = {Association for Computing Machinery},
  abstract            = {"Previous research in psychology has found that human faces have the capability of being more distracting under high perceptual load conditions compared to non-face objects. 
This project aims to assess the distracting potential of robot faces based on their human-likeliness. As a first step, this paper reports on our initial findings based on an online study.
We used a letter search task where participants had to search for a target letter within a circle of 6 letters, whilst an irrelevant distractor image was also present. 
The results of our experiment replicated previous results with human faces and non-face objects. Additionally, in the tasks where the irrelevant distractors are images of robot faces, the human-likeness of the robot influenced the response time (RT). 
Interestingly, the robot Alter produced results significantly different than all other distractor robots. 
The outcome of this is a distraction model related to human-likeness of robots. Our results show the impact of anthropomorphism on distracting potential and thus should be taken into account when designing robots."},
  keywords = {anthropomorphism, robot design, human-likeness, perception load},
  doi = {10.1145/3434074.3447137}
}

@misc{zolna2021method,
  bibtex_show={true},
  title={Method of handwritten character recognition confirmation},
  author={Zolna, Konrad and Asselborn, Thibault and Johal, Wafa},
  year={2021},
  month=nov # "~2",
  publisher={Google Patents},
  note={US Patent 11,164,025}
}
@inproceedings{johal2021robots,
  title={Robots for Learning-Learner-Centred Design},
  author={Johal, Wafa and Bruno, Barbara and Olsen, Jennifer K and Chetouani, Mohamed and Lemaignan, S{\'e}verin and Sandygulova, Anara},
  booktitle={Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={715--716},
  year={2021}
}
@article{asselborn2021transferability,
  bibtex_show={true},
  title={The transferability of handwriting skills: from the Cyrillic to the Latin alphabet},
  author={Asselborn, Thibault and Johal, Wafa and Tleubayev, Bolat and Zhexenova, Zhanel and Dillenbourg, Pierre and McBride, Catherine and Sandygulova, Anara},
  journal={npj Science of Learning},
  volume={6},
  number={1},
  pages={6},
  year={2021},
  publisher={Nature Publishing Group UK London}
}


%%%%% 2020
@article{johal2020research,
  bibtex_show={true},
  title={Research Trends in Social Robots for Learning},
  author={Johal, Wafa},
  journal={Current Robotics Reports},
  pages={1--9},
  year={2020},
  publisher={Springer International Publishing},
  selected = 	 {yes}
}

@inproceedings{yadollahi2020exploring,
  bibtex_show={true},
  title={Exploring the Role of Perspective Taking in Educational Child-Robot Interaction},
  author={Yadollahi, Elmira and Couto, Marta and Johal, Wafa and Dillenbourg, Pierre and Paiva, Ana},
  booktitle={International Conference on Artificial Intelligence in Education},
  pages={346--351},
  year={2020},
  organization={Springer, Cham}
}

@article{gargot2020acquisition,
  bibtex_show={true},
  title={Acquisition of handwriting in children with and without dysgraphia: A computational approach},
  author={Gargot, Thomas and Asselborn, Thibault and Pellerin, Hugues and Zammouri, Ingrid and M. Anzalone, Salvatore and Casteran, Laurence and Johal, Wafa and Dillenbourg, Pierre and Cohen, David and Jolly, Caroline},
  journal={Plos one},
  volume={15},
  number={9},
  pages={e0237575},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{johal2020Swarm,
  bibtex_show={true},
author = {Johal, Wafa and Peng, Yu and Mi, Haipeng},
title = {Swarm Robots in Education: A Review of Challenges and Opportunities},
year = {2020},
isbn = {9781450380546},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406499.3418755},
doi = {10.1145/3406499.3418755},
abstract = {This study reviews published scientific literature on the use of swarm robots for education purposes in the last ten years. It focuses on user studies involving robotics swarm in order to identify the potential contributions of the incorporation of swarm robots as an educational tool and insight future research. We consider here the appearance of swarm robots, the curriculum of the experimental task and the interaction modalities between learners and robots. The outcomes of the literature review are discussed in terms of their existing challenges and opportunities for guiding researchers, educators, and practitioners.},
booktitle = {Proceedings of the 8th International Conference on Human-Agent Interaction},
pages = {272–274},
numpages = {3},
keywords = {educational tool, swarm robots, literature review, learning, multi-robot},
location = {Virtual Event, USA},
series = {HAI '20}
}

@article{gargot2020p,
  bibtex_show={true},
  title={P. 114 Automatic assessment of motors impairments in autism spectrum disorders: a systematic review},
  author={Gargot, T and Archambault, D and Chetouani, M and Cohen, D and Johal, W and Anzalone, SM},
  journal={European Neuropsychopharmacology},
  volume={40},
  pages={S71--S72},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{chibaudel2020,
  bibtex_show={true},
author = {Chibaudel, Quentin and Johal, Wafa and Oriola, Bernard and J-M Mac\'{e}, Marc and Dillenbourg, Pierre and Tartas, Val\'{e}rie and Jouffrais, Christophe},
title = {"If You've Gone Straight, Now, You Must Turn Left" - Exploring the Use of a Tangible Interface in a Collaborative Treasure Hunt for People with Visual Impairments},
year = {2020},
isbn = {9781450371032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373625.3417020},
doi = {10.1145/3373625.3417020},
abstract = {Tangible User Interfaces (TUI) have been found to be relevant tools for collaborative learning by providing a shared workspace and enhancing joint visual attention. Researchers have explored the use of TUIs in a variety of curricular activities and found them particularly interesting for spatial exploration. However, very few studies have explored how TUIs could be used as a collaborative medium for people with visual impairments (VIs). In this study, we investigated the effect of tangible interaction (a small tangible robot) in a spatial collaborative task (a treasure hunt) involving two people with VIs. The aim was to evaluate the impact of the design of the TUI on the collaboration and the strategies used to perform the task. The experiment involved six dyads of people with VIs. The results showed that the collaboration was impacted by the interaction design and open interesting perspectives on the design of collaborative games for people with VIs.},
booktitle = {The 22nd International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {19},
numpages = {10},
keywords = {Spatial cognition, Game, Wayfinding, Robots, Non-visual interaction, Maps, Learning, Haptics, 3D model},
location = {Virtual Event, Greece},
series = {ASSETS '20}
}

@ARTICLE{zhanel2020,
  bibtex_show={true},
AUTHOR={Zhexenova, Zhanel and Amirova, Aida and Abdikarimova, Manshuk and Kudaibergenov, Kuanysh and Baimakhan, Nurakhmet and Tleubayev, Bolat and Asselborn, Thibault and Johal, Wafa and Dillenbourg, Pierre and CohenMiller, Anna and Sandygulova, Anara},   
TITLE={A Comparison of Social Robot to Tablet and Teacher in a New Script Learning Context},      
JOURNAL={Frontiers in Robotics and AI},      
VOLUME={7},      
PAGES={99},     
YEAR={2020},        
URL={https://www.frontiersin.org/article/10.3389/frobt.2020.00099},       
DOI={10.3389/frobt.2020.00099},      	
ISSN={2296-9144},    
ABSTRACT={This research occurred in a special context where Kazakhstan's recent decision to switch from Cyrillic to the Latin-based alphabet has resulted in challenges connected to teaching literacy, addressing a rare combination of research hypotheses and technical objectives about language learning. Teachers are not necessarily trained to teach the new alphabet, and this could result in a challenge for children with learning difficulties. Prior research studies in Human-Robot Interaction (HRI) have proposed the use of a robot to teach handwriting to children (Hood et al., <xref ref-type="bibr" rid="B28">2015</xref>; Lemaignan et al., <xref ref-type="bibr" rid="B44">2016</xref>). Drawing on the Kazakhstani case, our study takes an interdisciplinary approach by bringing together smart solutions from robotics, computer vision areas, and educational frameworks, language, and cognitive studies that will benefit diverse groups of stakeholders. In this study, a human-robot interaction application is designed to help primary school children learn both a newly-adopted script and also its handwriting system. The setup involved an experiment with 62 children between the ages of 7–9 years old, across three conditions: a robot and a tablet, a tablet only, and a teacher. Based on the paradigm—learning by teaching—the study showed that children improved their knowledge of the Latin script by interacting with a robot. Findings reported that children gained similar knowledge of a new script in all three conditions without gender effect. In addition, children's likeability ratings and positive mood change scores demonstrate significant benefits favoring the robot over a traditional teacher and tablet only approaches.}
}
@inproceedings{obaid2020domestic,
  bibtex_show={true},
  title={Domestic drones: Context of use in research literature},
  author={Obaid, Mohammad and Johal, Wafa and Mubin, Omar},
  booktitle={Proceedings of the 8th International Conference on Human-Agent Interaction},
  pages={196--203},
  year={2020}
}

@article{gargot2020acquisition,
  bibtex_show={true},
  title={Acquisition of handwriting in children with and without dysgraphia: A computational approach},
  author={Gargot, Thomas and Asselborn, Thibault and Pellerin, Hugues and Zammouri, Ingrid and M. Anzalone, Salvatore and Casteran, Laurence and Johal, Wafa and Dillenbourg, Pierre and Cohen, David and Jolly, Caroline},
  journal={PloS one},
  volume={15},
  number={9},
  pages={e0237575},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{guneysu2020gamified,
  bibtex_show={true},
  title={Gamified motor training with tangible robots in older adults: a feasibility study and comparison with the young},
  author={Guneysu Ozgur, Arzu and Wessel, Maximilian J and Olsen, Jennifer K and Johal, Wafa and Ozgur, Ayberk and Hummel, Friedhelm C and Dillenbourg, Pierre},
  journal={Frontiers in aging neuroscience},
  volume={12},
  pages={59},
  year={2020},
  publisher={Frontiers Media SA}
}

@inproceedings{sandygulova2020cowriting,
  bibtex_show={true},
  title={Cowriting kazakh: learning a new script with a robot},
  author={Sandygulova, Anara and Johal, Wafa and Zhexenova, Zhanel and Tleubayev, Bolat and Zhanatkyzy, Aida and Turarova, Aizada and Telisheva, Zhansaule and CohenMiller, Anna and Asselborn, Thibault and Dillenbourg, Pierre},
  booktitle={Proceedings of the 2020 ACM/IEEE international conference on human-robot interaction},
  pages={113--120},
  year={2020}
}

@inproceedings{khodr2020allohaptic,
  bibtex_show={true},
  title={Allohaptic: Robot-mediated haptic collaboration for learning linear functions},
  author={Khodr, Hala and Kianzad, Soheil and Johal, Wafa and Kothiyal, Aditi and Bruno, Barbara and Dillenbourg, Pierre},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={27--34},
  year={2020},
  organization={IEEE}
}
@inproceedings{neto2020using,
  bibtex_show={true},
  title={Using tabletop robots to promote inclusive classroom experiences},
  author={Neto, Isabel and Johal, Wafa and Couto, Marta and Nicolau, Hugo and Paiva, Ana and Guneysu, Arzu},
  booktitle={Proceedings of the interaction design and children conference},
  pages={281--292},
  year={2020}
}
@article{guneysu2020iterative,
  bibtex_show={true},
  title={Iterative design and evaluation of a tangible robot-assisted handwriting activity for special education},
  author={Guneysu Ozgur, Arzu and {\"O}zg{\"u}r, Ayberk and Asselborn, Thibault and Johal, Wafa and Yadollahi, Elmira and Bruno, Barbara and Skweres, Melissa and Dillenbourg, Pierre},
  journal={Frontiers in Robotics and AI},
  volume={7},
  pages={29},
  year={2020},
  publisher={Frontiers Media SA}
}
@inproceedings{johal2020learning,
  bibtex_show={true},
  title={Learning symmetry with tangible robots},
  author={Johal, Wafa and Andersen, Sonia and Chevalier, Morgane and Ozgur, Ayberk and Mondada, Francesco and Dillenbourg, Pierre},
  booktitle={Robotics in Education: Current Research and Innovations 10},
  pages={270--283},
  year={2020},
  organization={Springer}
}

@inproceedings{yadollahi2020exploring,
  bibtex_show={true},
  title={Exploring the role of perspective taking in educational child-robot interaction},
  author={Yadollahi, Elmira and Couto, Marta and Johal, Wafa and Dillenbourg, Pierre and Paiva, Ana},
  booktitle={Artificial Intelligence in Education: 21st International Conference, AIED 2020, Ifrane, Morocco, July 6--10, 2020, Proceedings, Part II 21},
  pages={346--351},
  year={2020},
  organization={Springer}
}

@inproceedings{johal2019tip,
  bibtex_show={true},
  title={Tip: Tangible e-ink paper manipulatives for classroom orchestration},
  author={Johal, Wafa and Tran, Alex and Khodr, Hala and {\"O}zg{\"u}r, Ayberk and Dillenbourg, Pierre},
  booktitle={Proceedings of the 31st Australian Conference on Human-Computer-Interaction},
  pages={595--598},
  year={2010}
}




